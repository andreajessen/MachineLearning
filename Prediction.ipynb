{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import splitfolders\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch import nn\n",
    "import copy\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import sys\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE = \"baseline\"\n",
    "BILATERAL = \"bilateral\"\n",
    "CANNY = 'canny'\n",
    "CLAHE = 'clahe'\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, parameter_dict, loader=default_loader, is_valid_file=None):\n",
    "        super(Dataset, self).__init__(root=root, loader=loader, is_valid_file=is_valid_file)\n",
    "        assert 'gray_scale' in parameter_dict\n",
    "        self.gray_scale = parameter_dict['gray_scale']\n",
    "        self.mean = IMAGENET_DEFAULT_MEAN\n",
    "        self.std = IMAGENET_DEFAULT_STD\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path, target = self.samples[index]\n",
    "        img = cv2.imread(image_path)\n",
    "        if self.gray_scale:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            self.mean = [0.5]\n",
    "            self.std = [0.5]\n",
    "        tensor = transforms.ToTensor()(img)\n",
    "        sample = transforms.Normalize(self.mean, self.std)(tensor)\n",
    "        return sample, target, index\n",
    "        \n",
    "class NoiseReductionDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, parameter_dict, loader=default_loader, is_valid_file=None):\n",
    "        super(NoiseReductionDataset, self).__init__(root=root, loader=loader, is_valid_file=is_valid_file)\n",
    "        assert 'gray_scale' in parameter_dict\n",
    "        assert 'd' in parameter_dict\n",
    "        assert 'sigmaColor' in parameter_dict\n",
    "        assert 'sigmaSpace' in parameter_dict\n",
    "\n",
    "        self.gray_scale = parameter_dict['gray_scale']\n",
    "        self.mean = IMAGENET_DEFAULT_MEAN\n",
    "        self.std = IMAGENET_DEFAULT_STD\n",
    "        self.d = parameter_dict['d']\n",
    "        self.sigmaColor = parameter_dict['sigmaColor']\n",
    "        self.sigmaSpace = parameter_dict['sigmaSpace']\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path, target = self.samples[index]\n",
    "        img = cv2.imread(image_path)\n",
    "        if self.gray_scale:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            self.mean = [0.5]\n",
    "            self.std = [0.5]\n",
    "        ## OBS: not sure about d, sigmaColor and sigmaSpace (15, 75, 75)\n",
    "        noiseless = cv2.bilateralFilter(img, self.d, self.sigmaColor, self.sigmaSpace)\n",
    "        tensor = transforms.ToTensor()(noiseless)\n",
    "        sample = transforms.Normalize(self.mean, self.std)(tensor)\n",
    "        return sample, target, index\n",
    "\n",
    "class EdgeDetectionDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, parameter_dict, loader=default_loader, is_valid_file=None):\n",
    "        super(EdgeDetectionDataset, self).__init__(root=root, loader=loader, is_valid_file=is_valid_file)\n",
    "        assert 'gray_scale' in parameter_dict\n",
    "        assert 'low_tresh' in parameter_dict\n",
    "        assert 'high_tresh' in parameter_dict\n",
    "\n",
    "        self.gray_scale = parameter_dict['gray_scale']\n",
    "        self.mean = IMAGENET_DEFAULT_MEAN\n",
    "        self.std = IMAGENET_DEFAULT_STD\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path, target = self.samples[index]\n",
    "        img = cv2.imread(image_path)\n",
    "        if self.gray_scale:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            self.mean = [0.5]\n",
    "            self.std = [0.5]\n",
    "        ## OBS: not sure about minVal and maxVal (100, 200) also need to look at aperture_size (size of Sobel kernel) and  L2gradient\n",
    "        edge = cv2.Canny(img, parameter_dict['low_tresh'], parameter_dict['high_tresh'])\n",
    "        tensor = transforms.ToTensor()(edge)\n",
    "        sample = transforms.Normalize(self.mean, self.std)(tensor)\n",
    "        return sample, target, index\n",
    "\n",
    "class ContrastEnhancingDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, parameter_dict, loader=default_loader, is_valid_file=None):\n",
    "        super(ContrastEnhancingDataset, self).__init__(root=root, loader=loader, is_valid_file=is_valid_file)\n",
    "        assert 'gray_scale' in parameter_dict\n",
    "        assert 'clipLimit' in parameter_dict\n",
    "        assert 'tileGridSize' in parameter_dict\n",
    "\n",
    "        self.gray_scale = parameter_dict['gray_scale']\n",
    "        self.mean = IMAGENET_DEFAULT_MEAN\n",
    "        self.std = IMAGENET_DEFAULT_STD\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path, target = self.samples[index]\n",
    "        img = cv2.imread(image_path)\n",
    "        if self.gray_scale:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            self.mean = [0.5]\n",
    "            self.std = [0.5]\n",
    "        ## OBS: not sure about clipLimit=2.0, tileGridSize=(8,8)\n",
    "        clahe = cv2.createCLAHE(clipLimit=parameter_dict['clipLimit'], tileGridSize=parameter_dict['tileGridSize'])\n",
    "        enhanced = clahe.apply(img)\n",
    "        tensor = transforms.ToTensor()(enhanced)\n",
    "        sample = transforms.Normalize(self.mean, self.std)(tensor)\n",
    "        return sample, target, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(root_dir, mode, classe, parameter_dict):\n",
    "    path = os.path.join(root_dir, mode)\n",
    "    dataset = classe(path, parameter_dict)\n",
    "    return dataset\n",
    "\n",
    "def dataloader(root_dir, mode, classe, parameter_dict):\n",
    "    dataset = get_dataset(root_dir, mode, classe, parameter_dict)\n",
    "    # Can have batchsize in dataloader\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        shuffle = True\n",
    "    )\n",
    "    return data_loader, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNet(nn.Module):\n",
    "    def __init__(self, gray_scale=False):\n",
    "        super().__init__()\n",
    "        input_dimention = 1 if gray_scale else 3\n",
    "        self.conv1 = nn.Conv2d(input_dimention, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(73926, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 'model_07_01_2022_15:52:55_model.pth'\n",
    "\n",
    "model_path = 'models/bilateral_grey_20_01_2022_17:27:39_model.pth'\n",
    "\n",
    "RUN_TYPE = BILATERAL\n",
    "GRAY_SCALE = True\n",
    "root_dir = 'Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  bilateral  with grayscale  True\n"
     ]
    }
   ],
   "source": [
    "if RUN_TYPE == BASELINE:\n",
    "    dataloder_test, dataset_test = dataloader(root_dir, \"test\", Dataset, {'gray_scale': GRAY_SCALE})\n",
    "elif RUN_TYPE == BILATERAL:\n",
    "    # Bilateral\n",
    "    parameter_dict = {'gray_scale': GRAY_SCALE, 'd': 15, 'sigmaColor': 50, 'sigmaSpace': 100}\n",
    "    dataloder_test, dataset_test = dataloader(root_dir, \"test\", NoiseReductionDataset, parameter_dict )\n",
    "elif RUN_TYPE == CANNY:\n",
    "    parameter_dict = {'gray_scale': GRAY_SCALE, 'low_tresh': 50, 'high_tresh': 230}\n",
    "    dataloder_test, dataset_test = dataloader(root_dir, \"test\", EdgeDetectionDataset, parameter_dict )\n",
    "elif RUN_TYPE == CLAHE:\n",
    "    parameter_dict = {'gray_scale': GRAY_SCALE, 'clipLimit': 1.0, 'tileGridSize': (8,8)}\n",
    "    dataloder_test, dataset_test = dataloader(root_dir, \"test\", ContrastEnhancingDataset, parameter_dict )\n",
    "else:\n",
    "    raise Exception(\"Unknown run tpye\")\n",
    "\n",
    "print(\"testing \", RUN_TYPE, \" with grayscale \", GRAY_SCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 6000, classes in dataset: ['Negative', 'Positive']\n",
      "Shape of image: torch.Size([64, 1, 227, 227])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of dataset: {len(dataset_test)}, classes in dataset: {dataset_test.classes}\")\n",
    "inputs, classes, indices = next(iter(dataloder_test))\n",
    "print(\"Shape of image:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:[====================] 100.27%Accuracy for class Negative is: 98.9 %\n",
      "Accuracy for class Positive is: 97.4 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in dataset_test.classes}\n",
    "total_pred = {classname: 0 for classname in dataset_test.classes}\n",
    "classlabels = {0: 'Negative', 1: 'Positive'}\n",
    "\n",
    "full_pred_list = []\n",
    "full_ground_truth = []\n",
    "# again no gradients needed\n",
    "i=0\n",
    "with torch.no_grad():\n",
    "    for data in dataloder_test:\n",
    "        i+=1\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        # Print loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        percentage = 100/len(dataset_test)*BATCH_SIZE*i\n",
    "        sys.stdout.write(\"Prediction:[%-20s] %.2f%%\" % ('='*round(percentage/5), percentage))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            full_pred_list.append(prediction.item())\n",
    "            full_ground_truth.append(label.item())\n",
    "            classs = label.item()\n",
    "            if label == prediction:\n",
    "                correct_pred[classlabels[classs]] += 1\n",
    "            total_pred[classlabels[classs]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix):\n",
    "\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "\n",
    "    ax.set_title('Confusion Matrix\\n\\n')\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ')\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(['False','True'])\n",
    "    ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(ground_truth, predictions):\n",
    "    '''\n",
    "        Function for plotting the confusion_matrix\n",
    "        Inputs:\n",
    "            predicitons: Predicitons from a keras model\n",
    "\n",
    "    '''\n",
    "    target_names = ['Negative (0)', 'Positive (1)']\n",
    "    print(classification_report(ground_truth, predictions, target_names=target_names, digits=4))\n",
    "    print(accuracy_score(ground_truth, predictions))\n",
    "    cf_matrix = confusion_matrix(ground_truth, predictions)\n",
    "    plot_confusion_matrix(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negative (0)     0.9747    0.9887    0.9816      3000\n",
      "Positive (1)     0.9885    0.9743    0.9814      3000\n",
      "\n",
      "    accuracy                         0.9815      6000\n",
      "   macro avg     0.9816    0.9815    0.9815      6000\n",
      "weighted avg     0.9816    0.9815    0.9815      6000\n",
      "\n",
      "0.9815\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation(full_ground_truth, full_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
